
# AutoML Streamlit Application

This Streamlit application offers a seamless interface for uploading CSV files to Google Cloud Storage (GCS) and managing BigQuery datasets. The application is designed to simplify the process of importing, analyzing, and utilizing data in BigQuery, with additional support for machine learning (ML) model training and predictions.

## Features

#### 1. Upload CSV Files to GCS
- Users can easily upload CSV files to **Google Cloud Storage (GCS)**, where they can be processed and ingested into **BigQuery**.
- The application facilitates seamless data transfer, allowing users to work directly with their files without needing to leave the platform.

#### 2. Dynamic Dataset and Table Management
- After uploading the CSV file, users can view a list of existing datasets and tables in the selected **BigQuery** project.
- The app allows users to select a dataset and automatically displays the tables contained within it.
- This feature streamlines data exploration and enables quick access to relevant datasets for analysis or modeling.

#### 3. Automatic Data Ingestion into BigQuery
- Upon uploading the file, the application parses the file based on a specific naming convention:
    ```text
    dataset_name-table_name-mode__filename.csv
    ```
- A **Cloud Function** processes the file, intelligently detecting and assigning appropriate data types to each column (e.g., string, integer, float, date).
- The table is then created or updated in **BigQuery** with the correct schema, making it ready for analysis.

#### 4. ML Model Training and Retraining
- The application allows users to train or re-train machine learning models directly within **BigQuery**.
- Users can manually specify the target column for prediction, or let the system auto-detect it based on the datasetâ€™s features.
- The system applies a **default configuration** unless the user opts to customize hyperparameters, model type, or training options.

#### 5. Prediction Interface
- After training the model, users can input feature values through the appâ€™s intuitive interface.
- The trained model will output predictions based on the input data, with results displayed immediately.
- This feature makes it easy for users to generate predictions without writing any code or managing complex workflows.


## Cloud Architecture

![Demo GIF](assets/Demo.gif)


## Key Benefits

- Ease of Use: No technical expertise is required to upload data, train models, or run predictions.

- Customizable Workflow: Users can tailor the configuration of the machine learning pipeline to suit their specific needs or rely on the default auto-detection for a quick setup.

- Streamlined Integration: The entire process, from data upload to prediction, is fully integrated, ensuring a smooth user experience.

## Project Structure

```text
ğŸ“¦bigquery-streamlit/
â”œâ”€â”€ ğŸ“‚prototype/
â”‚   â”œâ”€â”€ ğŸ“‚.streamlit/
â”‚   â”‚   â””â”€â”€ secrets.toml          # GCP credentials and config
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚components/
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Makes folder a Python package
â”‚   â”‚   â”œâ”€â”€ gcp_clients.py        # GCP service clients (BigQuery, Storage)
â”‚   â”‚   â”œâ”€â”€ navigation.py         # State management and routing
â”‚   â”‚   â”œâ”€â”€ prediction_form.py    # Prediction form for user input
â”‚   â”‚   â””â”€â”€ train_model.py        # Training new model, retrain model functionality
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚pages/
â”‚   â”‚   â”œâ”€â”€ __init__.py           
â”‚   â”‚   â”œâ”€â”€ Dataset_Selection.py
â”‚   â”‚   â”œâ”€â”€ Table_Selection.py
â”‚   â”‚   â”œâ”€â”€ File_Upload.py
â”‚   â”‚   â””â”€â”€ Prediction.py          
â”‚   â”‚
â”‚   â”œâ”€â”€ app.py                  # Main application entry point
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚services/
â”‚   â”œâ”€â”€ ğŸ“‚Cloud_functions/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚gcs_to_bq/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“‚BQ_SQL/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py          
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ backup_manager.py                
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data_cleaner.py                  
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data_quality_analyzer.py   
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ validator.py 
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”‚   â”‚   â””â”€â”€ Dockerfile               
â”‚   â”œâ”€â”€ ğŸ“‚ML/
â”‚   â”‚   â”œâ”€â”€ main.py          
â”‚   â”‚   â”œâ”€â”€ model_train.py          
â”‚   â”‚   â”œâ”€â”€ model_definition.py                  
â”‚   â”‚   â”œâ”€â”€ requirements.txt   
â”‚   â”‚   â””â”€â”€ Dockerfile            # Exposed on Port 81       
â”‚   â”œâ”€â”€ ğŸ“‚Predict/
â”‚   â”‚   â”œâ”€â”€ main.py          
â”‚   â”‚   â”œâ”€â”€ predict.py          
â”‚   â”‚   â”œâ”€â”€ model_definition.py                
â”‚   â”‚   â”œâ”€â”€ requirements.txt   
â”‚   â”‚   â””â”€â”€ Dockerfile            # Exposed on Port 81 
â”‚   â””â”€â”€ğŸ’²setup.sh                  # Main application entry point
â”‚
â”œâ”€â”€ ğŸ“‚assets/
â”‚   â””â”€â”€ Demo.gif/  
â”œâ”€â”€ .gitignore              # Github ignore files/folders
â””â”€â”€ â„¹ï¸README.md               # Project documentation
```